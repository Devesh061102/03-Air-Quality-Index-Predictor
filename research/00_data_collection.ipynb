{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML-Projects\\\\03-Air-Quality-Index-Predictor\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML-Projects\\\\03-Air-Quality-Index-Predictor'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataCollectionConfig:\n",
    "    root_dir: Path\n",
    "    api_key: str\n",
    "    city_info: dict\n",
    "    start_date: datetime\n",
    "    end_date: datetime\n",
    "    output_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Air_Quality_Predictor.constants import *\n",
    "from Air_Quality_Predictor.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_collection_config(self) -> DataCollectionConfig:\n",
    "        config = self.config.data_collection\n",
    "        \n",
    "        data_collection_config = DataCollectionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            api_key = config.api_key,\n",
    "            city_info = config.city_info,\n",
    "            start_date = datetime.strptime(config['start_date'], \"%Y-%m-%d\"),\n",
    "            end_date = datetime.strptime(config['end_date'], \"%Y-%m-%d\"),\n",
    "            output_file = config.output_file\n",
    "        )\n",
    "\n",
    "        return data_collection_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from pathlib import Path\n",
    "from Air_Quality_Predictor.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollection:\n",
    "    def __init__(self, config: DataCollectionConfig):\n",
    "        self.config = config\n",
    "        self.pollution_url = \"http://api.openweathermap.org/data/2.5/air_pollution/history\"\n",
    "        self.pollution_data_df = pd.DataFrame()\n",
    "\n",
    "    def fetch_pollution_data(self, lat: float, lon: float, start: datetime, end: datetime):\n",
    "        params = {\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "            \"start\": int(start.timestamp()),\n",
    "            \"end\": int(end.timestamp()),\n",
    "            \"appid\": self.config.api_key\n",
    "        }\n",
    "        response = requests.get(self.pollution_url, params=params)\n",
    "        return response\n",
    "\n",
    "    def collect_data(self):\n",
    "        current_date = self.config.start_date\n",
    "        months_fetched = 0\n",
    "\n",
    "        while current_date <= self.config.end_date:\n",
    "            end_of_month = (current_date.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
    "            if end_of_month > self.config.end_date:\n",
    "                end_of_month = self.config.end_date\n",
    "\n",
    "            pollution_response = self.fetch_pollution_data(self.config.city_info[\"lat\"], self.config.city_info[\"lon\"], current_date, end_of_month)\n",
    "            \n",
    "            if pollution_response.status_code == 200:\n",
    "                pollution_data = pollution_response.json()\n",
    "                \n",
    "                if pollution_data.get(\"list\"):\n",
    "                    daily_agg_pollution = {\n",
    "                        \"pm2_5\": 0,\n",
    "                        \"pm10\": 0,\n",
    "                        \"o3\": 0,\n",
    "                        \"no2\": 0,\n",
    "                        \"so2\": 0,\n",
    "                        \"co\": 0,\n",
    "                        \"count\": 0\n",
    "                    }\n",
    "                    for hourly_data in pollution_data[\"list\"]:\n",
    "                        daily_agg_pollution[\"pm2_5\"] += hourly_data[\"components\"].get(\"pm2_5\", 0)\n",
    "                        daily_agg_pollution[\"pm10\"] += hourly_data[\"components\"].get(\"pm10\", 0)\n",
    "                        daily_agg_pollution[\"o3\"] += hourly_data[\"components\"].get(\"o3\", 0)\n",
    "                        daily_agg_pollution[\"no2\"] += hourly_data[\"components\"].get(\"no2\", 0)\n",
    "                        daily_agg_pollution[\"so2\"] += hourly_data[\"components\"].get(\"so2\", 0)\n",
    "                        daily_agg_pollution[\"co\"] += hourly_data[\"components\"].get(\"co\", 0)\n",
    "                        daily_agg_pollution[\"count\"] += 1\n",
    "                    \n",
    "                    if daily_agg_pollution[\"count\"] > 0:\n",
    "                        pollution_row = {\n",
    "                            \"city\": self.config.city_info[\"city\"],\n",
    "                            \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                            \"pm2_5\": round(daily_agg_pollution[\"pm2_5\"] / daily_agg_pollution[\"count\"], 3),\n",
    "                            \"pm10\": round(daily_agg_pollution[\"pm10\"] / daily_agg_pollution[\"count\"], 3),\n",
    "                            \"o3\": round(daily_agg_pollution[\"o3\"] / daily_agg_pollution[\"count\"], 3),\n",
    "                            \"no2\": round(daily_agg_pollution[\"no2\"] / daily_agg_pollution[\"count\"], 3),\n",
    "                            \"so2\": round(daily_agg_pollution[\"so2\"] / daily_agg_pollution[\"count\"], 3),\n",
    "                            \"co\": round(daily_agg_pollution[\"co\"] / daily_agg_pollution[\"count\"], 3),\n",
    "                        }\n",
    "                        \n",
    "                        row_df = pd.DataFrame([pollution_row])\n",
    "                        self.pollution_data_df = pd.concat([self.pollution_data_df, row_df], ignore_index=True)\n",
    "            \n",
    "            else:\n",
    "                logger.error(f\"Error fetching pollution data for {self.config.city_info['city']} on {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "            current_date += timedelta(days=1)\n",
    "            if current_date.month != (current_date - timedelta(days=1)).month:\n",
    "                months_fetched += 1\n",
    "                logger.info(f\"Monthly data fetched: {months_fetched} months\")\n",
    "                logger.info(\"-\" * 50)\n",
    "            \n",
    "            # To ensure we do not exceed 60 requests per minute\n",
    "            time.sleep(1)\n",
    "\n",
    "    \n",
    "\n",
    "    def save_data(self):\n",
    "        city_name = self.config.city_info[\"city\"]\n",
    "        output_file = Path(self.config.output_file) / f\"{city_name}_pollutant_data.csv\"\n",
    "        self.pollution_data_df.to_csv(output_file, index=False)\n",
    "        logger.info(f\"Pollution data for {city_name} has been saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-03 07:35:28,447 : INFO : common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-06-03 07:35:28,447 : INFO : common : yaml file: params.yaml loaded successfully]\n",
      "[2024-06-03 07:35:28,447 : INFO : common : Created directory at: artifacts]\n",
      "[2024-06-03 07:36:28,152 : INFO : 2817069000 : Monthly data fetched: 1 months]\n",
      "[2024-06-03 07:36:28,152 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:37:22,958 : INFO : 2817069000 : Monthly data fetched: 2 months]\n",
      "[2024-06-03 07:37:22,958 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:38:20,881 : INFO : 2817069000 : Monthly data fetched: 3 months]\n",
      "[2024-06-03 07:38:20,881 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:39:14,618 : INFO : 2817069000 : Monthly data fetched: 4 months]\n",
      "[2024-06-03 07:39:14,618 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:40:21,608 : INFO : 2817069000 : Monthly data fetched: 5 months]\n",
      "[2024-06-03 07:40:21,609 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:41:15,851 : INFO : 2817069000 : Monthly data fetched: 6 months]\n",
      "[2024-06-03 07:41:15,851 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:42:11,927 : INFO : 2817069000 : Monthly data fetched: 7 months]\n",
      "[2024-06-03 07:42:11,929 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:43:09,899 : INFO : 2817069000 : Monthly data fetched: 8 months]\n",
      "[2024-06-03 07:43:09,900 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:44:01,623 : INFO : 2817069000 : Monthly data fetched: 9 months]\n",
      "[2024-06-03 07:44:01,623 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:45:00,817 : INFO : 2817069000 : Monthly data fetched: 10 months]\n",
      "[2024-06-03 07:45:00,817 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:45:54,962 : INFO : 2817069000 : Monthly data fetched: 11 months]\n",
      "[2024-06-03 07:45:54,963 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:46:51,982 : INFO : 2817069000 : Monthly data fetched: 12 months]\n",
      "[2024-06-03 07:46:51,984 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:47:54,133 : INFO : 2817069000 : Monthly data fetched: 13 months]\n",
      "[2024-06-03 07:47:54,135 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:48:48,961 : INFO : 2817069000 : Monthly data fetched: 14 months]\n",
      "[2024-06-03 07:48:48,961 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:49:53,842 : INFO : 2817069000 : Monthly data fetched: 15 months]\n",
      "[2024-06-03 07:49:53,842 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:50:53,078 : INFO : 2817069000 : Monthly data fetched: 16 months]\n",
      "[2024-06-03 07:50:53,078 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:51:47,482 : INFO : 2817069000 : Monthly data fetched: 17 months]\n",
      "[2024-06-03 07:51:47,482 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:52:42,353 : INFO : 2817069000 : Monthly data fetched: 18 months]\n",
      "[2024-06-03 07:52:42,353 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:53:38,463 : INFO : 2817069000 : Monthly data fetched: 19 months]\n",
      "[2024-06-03 07:53:38,463 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:54:35,355 : INFO : 2817069000 : Monthly data fetched: 20 months]\n",
      "[2024-06-03 07:54:35,357 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:55:29,114 : INFO : 2817069000 : Monthly data fetched: 21 months]\n",
      "[2024-06-03 07:55:29,115 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:56:29,944 : INFO : 2817069000 : Monthly data fetched: 22 months]\n",
      "[2024-06-03 07:56:29,945 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:57:26,130 : INFO : 2817069000 : Monthly data fetched: 23 months]\n",
      "[2024-06-03 07:57:26,131 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:58:21,993 : INFO : 2817069000 : Monthly data fetched: 24 months]\n",
      "[2024-06-03 07:58:21,994 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 07:59:22,167 : INFO : 2817069000 : Monthly data fetched: 25 months]\n",
      "[2024-06-03 07:59:22,168 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:00:21,724 : INFO : 2817069000 : Monthly data fetched: 26 months]\n",
      "[2024-06-03 08:00:21,726 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:01:21,788 : INFO : 2817069000 : Monthly data fetched: 27 months]\n",
      "[2024-06-03 08:01:21,788 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:02:17,436 : INFO : 2817069000 : Monthly data fetched: 28 months]\n",
      "[2024-06-03 08:02:17,437 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:03:13,567 : INFO : 2817069000 : Monthly data fetched: 29 months]\n",
      "[2024-06-03 08:03:13,567 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:04:09,345 : INFO : 2817069000 : Monthly data fetched: 30 months]\n",
      "[2024-06-03 08:04:09,346 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:05:09,702 : INFO : 2817069000 : Monthly data fetched: 31 months]\n",
      "[2024-06-03 08:05:09,703 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:06:07,059 : INFO : 2817069000 : Monthly data fetched: 32 months]\n",
      "[2024-06-03 08:06:07,059 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:07:00,908 : INFO : 2817069000 : Monthly data fetched: 33 months]\n",
      "[2024-06-03 08:07:00,909 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:08:00,242 : INFO : 2817069000 : Monthly data fetched: 34 months]\n",
      "[2024-06-03 08:08:00,243 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:09:01,375 : INFO : 2817069000 : Monthly data fetched: 35 months]\n",
      "[2024-06-03 08:09:01,375 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:09:59,350 : INFO : 2817069000 : Monthly data fetched: 36 months]\n",
      "[2024-06-03 08:09:59,351 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:10:56,071 : INFO : 2817069000 : Monthly data fetched: 37 months]\n",
      "[2024-06-03 08:10:56,071 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:11:48,369 : INFO : 2817069000 : Monthly data fetched: 38 months]\n",
      "[2024-06-03 08:11:48,370 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:12:45,683 : INFO : 2817069000 : Monthly data fetched: 39 months]\n",
      "[2024-06-03 08:12:45,684 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:13:39,175 : INFO : 2817069000 : Monthly data fetched: 40 months]\n",
      "[2024-06-03 08:13:39,176 : INFO : 2817069000 : --------------------------------------------------]\n",
      "[2024-06-03 08:14:36,237 : INFO : 2817069000 : Monthly data fetched: 41 months]\n",
      "[2024-06-03 08:14:36,238 : INFO : 2817069000 : --------------------------------------------------]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     data_collection\u001b[38;5;241m.\u001b[39msave_data()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     data_collection \u001b[38;5;241m=\u001b[39m DataCollection(config\u001b[38;5;241m=\u001b[39mdata_collection_config)\n\u001b[0;32m      6\u001b[0m     data_collection\u001b[38;5;241m.\u001b[39mcollect_data()\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mdata_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[7], line 80\u001b[0m, in \u001b[0;36mDataCollection.save_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     79\u001b[0m     city_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcity_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 80\u001b[0m     output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcity_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_pollutant_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpollution_data_df\u001b[38;5;241m.\u001b[39mto_csv(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPollution data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has been saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    data_collection_config = config_manager.get_data_collection_config()\n",
    "    data_collection = DataCollection(config=data_collection_config)\n",
    "    \n",
    "    data_collection.collect_data()\n",
    "    data_collection.save_data()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
